import cv2
import sys
import os
import numpy as np
import random

# unit box is 128x128
UnitSpacing = 128
ImgX = 1920
ImgY = 1080
Scales=[1, 1, 2, 2]
AspectRatios=[1, 2, 1, 2]
SkipFrames = 10

# read all of the args. args should be filenames of the ground truth
# data generated by ROIdemo.py.  These filenames must be numpy arrays
# and named with the format vidfilename_objname.npy
VideoGroundTruth = {}
for arg in sys.argv[1:]:
	gtarr = np.load(arg, allow_pickle=True)
	gttup = (int(gtarr[0]),int(gtarr[1]),int(gtarr[2]),int(gtarr[3]))
	fileName = os.path.split(arg[:arg.find('_')])[1]
	if fileName in VideoGroundTruth:
		VideoGroundTruth[fileName].append(gttup)
	else:
		VideoGroundTruth[fileName] = [gttup]
	img = cv2.imread("Output/FirstFrame/"+fileName+".jpg",cv2.IMREAD_GRAYSCALE)
	#cv2.rectangle(img,
	#cv2.imshow(fileName,img)
	#k = cv2.waitKey(100)


# Each video frame is 1920x1080 so I'm trying to break up each frame
# So I can have as many non-overlapping boxes that are 128x128 as
# possible.
# 1920/128 = 15
# 1080/128 ~= 8 so there will be some gaps. I'm ok with that.

# Generate all anchor points
def GenerateAnchorPoints():
	# calculate anchor point spacing along x
	nx = int(ImgX/UnitSpacing)
	# calculate anchor point spacing along y
	ny = int(ImgY/UnitSpacing)
	# calculate all of the X and Y anchor points
	apxs = np.array(range(0,nx))*(ImgX/nx)+UnitSpacing/2
	apys = np.array(range(0,ny))*(ImgY/ny)+UnitSpacing/2
	# combine all of the x/y combinations into a list
	aps=[]
	for apx in apxs:
		for apy in apys:
			tup = (int(apx),int(apy))
			aps.append(tup)
	return aps

# Generate boxes given the anchor points and
# a given scale and aspect ratio
def GenerateBoxes(anchors, scale, aspectRatio):
	boxes = []
	dx = (scale * UnitSpacing)/2
	dy = (dx * aspectRatio)/2
	for ap in anchors:
		# "center" of the box
		cx = min(max(dx,ap[0]),ImgX-1-dx)
		cy = min(max(dy,ap[1]),ImgY-1-dy)
		ux = cx-dx
		uy = cy-dy
		tup=(int(ux),int(uy),int(ux+2*dx),int(uy+2*dy))
		boxes.append(tup)
	return boxes

def CalcOverlap(face, box):
	fx1 = face[0]
	fx2 = face[0]+face[2]
	fy1 = face[1]
	fy2 = face[1]+face[3]
	fa = face[2]*face[3]

	bx1 = box[0]
	bx2 = box[0]+box[2]
	by1 = box[1]
	by2 = box[1]+box[3]
	ba = box[2]*box[3]

	ia = max(0,min(fx2,bx2)-max(fx1,bx1))*max(0,min(fy2,by2)-max(fy1,by1))
	ratio = float(ia)/float(ba+fa-ia)
	return ratio

def BuildTrainBoxes(faces, boxes):
	boxes = list(boxes) # copy the boxes list
	faceBoxes = []
	# for each face...
	for face in faces:
		bestth = 0
		bestidx = -1
		idx = 0
		# for each box
		for box in boxes:
			# calculate the IoU
			th = CalcOverlap(face, box)
			# keep the best one
			if th > bestth:
				bestth = th
				bestidx = idx
			idx = idx + 1

		# if we found a good box
		if bestth > 0:
			print("best threshold: " + str(bestth))
			# keep the best box which matches the face
			faceBoxes.append(boxes[bestidx])
			# remove the box from boxes list
			boxes.remove(boxes[bestidx])

	return faceBoxes, boxes

def ExtractBox(img, box, shape):
	sub = img[box[1]:box[1]+shape[1],box[0]:box[0]+shape[0]]
	return sub

print("Calculating total frames...")
totalFrames = 0
for videoName in VideoGroundTruth:
	cap = cv2.VideoCapture("videos/BackCameraClips/" + videoName + ".mp4")
	totalFrames = totalFrames +  int(cap.get(cv2.CAP_PROP_FRAME_COUNT)/SkipFrames)

print("Using " + str(totalFrames) + " frames.")

aps = GenerateAnchorPoints()
for scale, aspectRatio in zip(Scales, AspectRatios):
	height = UnitSpacing*scale;
	width = height*aspectRatio
	boxShape = (width, height)
	y = np.zeros((totalFrames,))
	X = np.zeros((totalFrames,boxShape[0],boxShape[1]))
	boxes = GenerateBoxes(aps, scale, aspectRatio)
	fno = 0
	for videoName in VideoGroundTruth:
		cap = cv2.VideoCapture("videos/BackCameraClips/" + videoName + ".mp4")
		faces = VideoGroundTruth[videoName]
		faceBoxes, otherBoxes = BuildTrainBoxes(faces,boxes)
		while True:
			ret, frame = cap.read()
			if ret == False:
				break

			# Convert to grayscale
			gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

			# Extract faceboxes
			for face in faceBoxes:
				data = ExtractBox(gray, face, boxShape)
				y[fno] = 1
				X[fno,:width,:height] = data

			random.shuffle(otherBoxes)
			# Extract other boxes
			for i in range(0,len(faceBoxes)):
				data = ExtractBox(gray, otherBoxes[i], boxShape)
				y[fno] = 0
				X[fno,:width,:height] = data

			if fno == 0:
				for face in faceBoxes:
					cv2.rectangle(gray,face[0:2],face[2:4],(0,0,0))
				for i in range(0,len(faceBoxes)):
					ob = otherBoxes[i]
					cv2.rectangle(gray,ob[0:2],ob[2:4],(255,0,0))
				cv2.imshow("frame 0", gray)
				cv2.waitKey(0)

			for i in range(0,SkipFrames):
				ret, frame = cap.read()

			fno = fno + 1
